import time

import polars as pl
import polars.selectors as cs

from bank_statement_parser.modules.classes.data_definitions import Config
from bank_statement_parser.modules.classes.errors import StatementError
from bank_statement_parser.modules.classes.statement_classes import Statement, StatementTable
from bank_statement_parser.modules.config import config_accounts, config_companies, config_company_accounts, config_standard_fields
from bank_statement_parser.modules.constants import NUMBERS_GBP, STRIP_GBP_USD
from bank_statement_parser.modules.currency import currency_spec
from bank_statement_parser.modules.functions.pdf_functions import page_crop, region_table
from bank_statement_parser.modules.functions.statement_functions import extract_table_fields, spawn_locations

log = []

# stmt = Statement("/home/boscorat/Downloads/2025-07-08_Statement_Advance_Account.pdf")
stmt = Statement("/home/boscorat/Downloads/2025-07-08_Statement_Flexible_Saver.pdf")
# stmt = Statement("/home/boscorat/Downloads/2025-07-12_Statement_Rewards_Credit_Card.pdf")
checks_and_balances: pl.DataFrame = pl.DataFrame()
DEBUG = False


def strip(data, field, spec=None):
    start = time.time()
    src = "raw"
    step = "strip"
    if DEBUG:
        print(f"{step}: {field.field}")
        print("Before...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data)
    data = data.with_columns(
        pl.col(f"value_{src}").fill_null("").alias(f"value_{step}"),
        pl.lit(False).alias(f"success_{step}"),
        pl.lit(f"{step} error").alias(f"error_{step}"),
    )
    if field.strip_characters_start:
        data = data.with_columns(
            pl.col(f"value_{step}").str.strip_chars_start(field.strip_characters_start).fill_null("").alias(f"value_{step}")
        )
    if field.strip_characters_end:
        data = data.with_columns(
            pl.col(f"value_{step}").str.strip_chars_end(field.strip_characters_end).fill_null("").alias(f"value_{step}")
        )

    if spec and field.type == "numeric":
        data = data.with_columns(
            pl.col(f"value_{step}")
            .str.replace_many(spec.symbols, [""])
            .str.replace_many(spec.seperators_thousands, [""])
            .str.replace_many([r"\s"], [""])
            .fill_null("")
            .alias(f"value_{step}")  # always remove any whitespace
        )

    data = data.with_columns(
        ((pl.col(f"value_{step}").is_not_null()) & (pl.col(f"value_{step}").str.len_bytes() > 0)).alias(f"success_{step}")
    ).with_columns(pl.when(pl.col(f"success_{step}")).then(None).otherwise(pl.col(f"error_{step}")).alias(f"error_{step}"))
    if DEBUG:
        print("After...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data)

    log.append(["strip", time.time() - start])
    return data


def build_pattern(string_pattern=None, spec_pattern=None, prefix=None, suffix=None):
    start = time.time()
    pattern: str = r".+"
    if string_pattern is not None:
        pattern = string_pattern
        log.append(["build_pattern", time.time() - start])
        return pattern
    elif spec_pattern is not None:
        pattern = spec_pattern
        if prefix is None and suffix is None:
            return pattern
        if prefix is not None:
            pattern = str(pattern).replace("^", rf"^({prefix})?\s?")
        if suffix is not None:
            pattern = str(pattern).replace("$", rf"\s?({suffix})?$")
    log.append(["build_pattern", time.time() - start])
    return pattern


def patmatch(data, field, spec=None):
    start = time.time()
    src = "strip"
    step = "pattern"
    pattern = build_pattern(
        string_pattern=field.string_pattern,
        spec_pattern=spec.pattern if spec else None,
        prefix=field.numeric_modifier.prefix if field.numeric_modifier else None,
        suffix=field.numeric_modifier.suffix if field.numeric_modifier else None,
    )
    if DEBUG:
        print(f"{step}: spec: {pattern}")
        print("Before...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data.collect())
    data = data.with_columns(
        pl.lit("").alias(f"value_{step}"),
        pl.lit(False).alias(f"success_{step}"),
        pl.lit(f"{step} error").alias(f"error_{step}"),
    )
    # if spec:
    #     data = data.with_columns(
    #         pl.col(f"value_{src}")
    #         .str.extract(
    #             spec.pattern,
    #             0,
    #         )
    #         .fill_null("")
    #         .alias(f"value_{step}")
    #     )
    # else:
    data = data.with_columns(pl.col(f"value_{src}").str.extract(pattern, 0).fill_null("").alias(f"value_{step}"))
    data = data.with_columns(
        ((pl.col(f"value_{step}").is_not_null()) & (pl.col(f"value_{step}").str.len_bytes() > 0)).alias(f"success_{step}")
    ).with_columns(pl.when(pl.col(f"success_{step}")).then(None).otherwise(pl.col(f"error_{step}")).alias(f"error_{step}"))
    if DEBUG:
        print("After...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data.collect())
    log.append(["pat_match", time.time() - start])
    return data


def cast(data, field):
    start = time.time()
    src = "pattern"
    step = "cast"
    if DEBUG:
        print(f"{step}: {field.numeric_modifier}")
        print("Before...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data)
    data = data.with_columns(
        pl.lit("").alias(f"value_{step}"),
        pl.lit(False).alias(f"success_{step}"),
        pl.lit(f"{step} error").alias(f"error_{step}"),
    )
    if field.type == "numeric":
        if field.numeric_modifier:
            if field.numeric_modifier.prefix or field.numeric_modifier.suffix:
                if field.numeric_modifier.prefix:
                    data = data.with_columns(
                        pl.when(pl.col(f"value_{src}").str.starts_with(field.numeric_modifier.prefix))
                        .then(
                            pl.col(f"value_{src}")
                            .str.strip_chars_start(field.numeric_modifier.prefix)
                            .cast(float)
                            .mul(field.numeric_modifier.multiplier)
                        )
                        .otherwise(pl.col(f"value_{src}").cast(float, strict=False))
                        .alias(f"value_{step}")
                    )
                elif field.numeric_modifier.suffix:
                    data = data.with_columns(
                        pl.when(pl.col(f"value_{src}").str.ends_with(field.numeric_modifier.suffix))
                        .then(
                            pl.col(f"value_{src}")
                            .str.strip_chars_end(field.numeric_modifier.suffix)
                            .cast(float, strict=False)
                            .mul(field.numeric_modifier.multiplier)
                        )
                        .otherwise(pl.col(f"value_{src}").cast(float, strict=False))
                        .alias(f"value_{step}")
                    )
            else:
                data = data.with_columns(
                    pl.col(f"value_{src}").cast(float, strict=False).mul(field.numeric_modifier.multiplier).alias(f"value_{step}")
                )
            if field.numeric_modifier.exclude_negative_values:
                data = data.with_columns(pl.when(pl.col(f"value_{step}") < 0).then(pl.lit(0.00)).alias(f"value_{step}"))
            if field.numeric_modifier.exclude_positive_values:
                data = data.with_columns(pl.when(pl.col(f"value_{step}") > 0).then(pl.lit(0.00)).alias(f"value_{step}"))
        else:
            data = data.with_columns(pl.col(f"value_{src}").cast(float, strict=False).alias(f"value_{step}"))
    elif field.type == "string":
        data = data.with_columns(pl.col(f"value_{src}").cast(str, strict=False).alias(f"value_{step}"))

    # cast the value back as a string so we don't get mixed types in the column value_cast column
    data = data.with_columns(pl.col(f"value_{step}").cast(str).fill_null("").alias(f"value_{step}"))
    if field.type == "numeric":
        data = data.with_columns(pl.col(f"value_{step}").str.to_decimal(scale=4).cast(str).alias(f"value_{step}"))

    data = data.with_columns(
        ((pl.col(f"value_{step}").is_not_null()) & (pl.col(f"value_{step}").str.len_bytes() > 0)).alias(f"success_{step}")
    ).with_columns(pl.when(pl.col(f"success_{step}")).then(None).otherwise(pl.col(f"error_{step}")).alias(f"error_{step}"))
    if DEBUG:
        print("After...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data)
    log.append(["cast", time.time() - start])
    return data


def trim(data, field):
    start = time.time()
    src = "cast"
    step = "trim"
    if DEBUG:
        print(f"{step}: {field.string_max_length}")
        print("Before...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data)
    data = data.with_columns(
        pl.lit("").alias(f"value_{step}"),
        pl.lit(False).alias(f"success_{step}"),
        pl.lit(f"{step} error").alias(f"error_{step}"),
    )
    string_max_length = field.string_max_length if field.string_max_length else 999
    if field.type == "string":
        data = data.with_columns(pl.col(f"value_{src}").str.head(string_max_length).fill_null("").alias(f"value_{step}"))
    else:
        data = data.with_columns(pl.col(f"value_{src}").fill_null("").alias(f"value_{step}"))
    data = data.with_columns(
        ((pl.col(f"value_{step}").is_not_null()) & (pl.col(f"value_{step}").str.len_bytes() > 0)).alias(f"success_{step}")
    ).with_columns(pl.when(pl.col(f"success_{step}")).then(None).otherwise(pl.col(f"error_{step}")).alias(f"error_{step}"))
    if DEBUG:
        print("After...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data)
    log.append(["trim", time.time() - start])
    return data


def validate(data, field):
    start = time.time()
    src = "trim"
    if DEBUG:
        print("Validate")
        print("Before...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data)

    data = data.with_columns(
        value=pl.col(f"value_{src}"),
        success=pl.concat_list(cs.starts_with("success_")).list.all(),
        error=pl.concat_list(cs.starts_with("error_")).list.drop_nulls().list.first(),
    ).with_columns(hard_fail=~pl.col("success") & field.vital)
    if DEBUG:
        print("After...")
        with pl.Config(tbl_cols=-1, tbl_rows=-1):
            print(data)
    log.append(["validate", time.time() - start])
    return data


def cleanup(data):
    start = time.time()
    if not DEBUG:
        data = data.select("section", "location", "config", "row", "page", "field", "vital", "value", "success", "error", "hard_fail")
    log.append(["cleanup", time.time() - start])
    return data


def extract_fields(pdf, location, statement_table, config_field, config, section, location_id):
    start = time.time()
    results: pl.DataFrame = pl.DataFrame()
    result: pl.LazyFrame = pl.LazyFrame()
    region, exception = get_region(location, pdf)
    if not statement_table:
        if region and not exception:
            result = pl.LazyFrame(
                data=[
                    pl.Series("field", [config_field.field], dtype=pl.String),
                    pl.Series("vital", [config_field.vital], dtype=pl.Boolean),
                    pl.Series("value_raw", [region.extract_text()], dtype=pl.String),
                ]
            )
            result = result.select(
                pl.lit(section).alias("section"),
                pl.lit(location_id).alias("location"),
                pl.lit(config).alias("config"),
                pl.lit(0).alias("row"),
                pl.lit(location.page_number).alias("page"),
                pl.col("field"),
                pl.col("vital"),
                pl.col("value_raw"),
            )
            spec = None
            if config_field.type == "numeric":
                spec = currency_spec[config_field.numeric_currency]
            result = (
                result.pipe(strip, config_field, spec)
                .pipe(patmatch, config_field, spec)
                .pipe(cast, config_field)
                .pipe(trim, config_field)
                .pipe(validate, config_field)
                .pipe(cleanup)
            )
            try:
                results.vstack(result.collect(), in_place=True)
            except pl.exceptions.ColumnNotFoundError:
                log.append(["extract_fields_exception", time.time() - start])
                return results.lazy()

    else:  # if there is a statement table
        table = get_table(location, region, statement_table) if region and not exception else pl.LazyFrame()
        table = table.collect().lazy()

        if not statement_table.transaction_spec:
            table_eager: pl.DataFrame = table.collect()
            for field in statement_table.fields:
                result = pl.LazyFrame(
                    data=[
                        pl.Series("field", [field.field], dtype=pl.String),
                        pl.Series("vital", [field.vital], dtype=pl.Boolean),
                        pl.Series("value_raw", [table_eager.item(field.cell.row, field.cell.col)], dtype=pl.String),
                    ]
                )
                result = result.select(
                    pl.lit(section).alias("section"),
                    pl.lit(location_id).alias("location"),
                    pl.lit(config).alias("config"),
                    pl.lit(field.cell.row).alias("row"),
                    pl.lit(location.page_number).alias("page"),
                    pl.col("field"),
                    pl.col("vital"),
                    pl.col("value_raw"),
                )
                spec = None
                if field.type == "numeric":
                    spec = currency_spec[field.numeric_currency]
                result = (
                    result.pipe(strip, field, spec)
                    .pipe(patmatch, field, spec)
                    .pipe(cast, field)
                    .pipe(trim, field)
                    .pipe(validate, field)
                    .pipe(cleanup)
                )
                try:
                    results.vstack(result.collect(), in_place=True)
                except pl.exceptions.ColumnNotFoundError:
                    continue

        else:  # transaction records will be multi-line and have now row specification
            for field in statement_table.fields:
                result = table.select(
                    section=pl.lit(section),
                    location=pl.lit(location_id),
                    config=pl.lit(config),
                    page=pl.lit(location.page_number),
                    field=pl.lit(field.field),
                    vital=pl.lit(field.vital),
                    value_raw=pl.nth(field.column),
                ).with_row_index("row")
                spec = None
                if field.type == "numeric":
                    spec = currency_spec[field.numeric_currency]
                result = (
                    result.pipe(strip, field, spec).pipe(patmatch, field, spec).pipe(cast, field).pipe(trim, field).pipe(validate, field)
                    # .pipe(cleanup)
                )
                try:
                    results.vstack(result.collect(), in_place=True)
                except pl.exceptions.ColumnNotFoundError:
                    continue
            # Transaction bookends
            bookends = statement_table.transaction_spec.transaction_bookends
            start_line = bookends.start_fields
            end_line = bookends.end_fields
            start_rows = (
                results.filter(pl.col("field").is_in(start_line))
                .group_by("row")
                .agg(pl.col("success").implode())
                .filter(pl.col("success").list.count_matches(True) >= bookends.min_non_empty_start)
                .select(pl.col("row"), transaction_start=pl.lit(True))
            )
            end_rows = (
                results.filter(pl.col("field").is_in(end_line))
                .group_by("row")
                .agg(pl.col("success").implode())
                .filter(pl.col("success").list.count_matches(True) >= bookends.min_non_empty_end)
                .select(pl.col("row"), transaction_end=pl.lit(True))
            )
            results = (
                results.join(start_rows, on="row", how="left", validate="m:1")
                .join(end_rows, on="row", how="left", validate="m:1")
                .with_columns(
                    transaction_start=pl.col("transaction_start").fill_null(False),
                    transaction_end=pl.col("transaction_end").fill_null(False),
                )
            )
    log.append([f"extract_fields_{'stmt' if statement_table and statement_table.transaction_spec else 'std'}", time.time() - start])
    return results.lazy()


def process_transactions(data, transaction_spec):
    start = time.time()
    data = (
        data.filter(pl.col("success"))
        .pivot(values="value", index=["page", "row", "transaction_start", "transaction_end"], on="field")
        .sort("page", "row")
        .lazy()
    )  # pivot the data
    data = data.with_columns(transaction_number=pl.col("transaction_start").cum_sum()).filter(
        pl.col("transaction_number") > 0
    )  # number the transactions and remove rows before the 1st
    if fffs := transaction_spec.fill_forward_fields:  # fill forward if there are any fields in the spec
        for fff in fffs:
            data = data.with_columns(
                pl.col(fff).fill_null(strategy="forward").alias(fff),
            )
    if mfs := transaction_spec.merge_fields:
        for mf in mfs.fields:
            data = data.with_columns(
                pl.col(mf).str.join(delimiter=mfs.separator).over("transaction_number"),
            )
    data = data.filter(pl.col("transaction_end")).drop("transaction_start", "transaction_end")

    log.append(["process_transactions", time.time() - start])
    return data.collect()


def get_results(pdf, section, config: Config, scope="success") -> pl.DataFrame:  # scope can be all, success, fail, or hard_fail
    start = time.time()
    result: pl.LazyFrame = pl.LazyFrame()
    results: pl.DataFrame = pl.DataFrame()
    locations = config.statement_table.locations if config.statement_table else config.locations
    spawned_locations = spawn_locations(locations, stmt.pdf)
    for i, location in enumerate(spawned_locations):
        result = extract_fields(pdf, location, config.statement_table, config.field, config.config, section=section, location_id=i)
        results.vstack(result.collect(), in_place=True)

    if statement_table := config.statement_table:
        # process transactions if there's a transaction spec
        if spec := statement_table.transaction_spec:
            results = results.pipe(process_transactions, spec)
            log.append(["get_results_stmt_transaction", time.time() - start])
            return results

    if scope == "all":
        log.append(["get_results_all", time.time() - start])
        return results
    elif scope == "success":
        log.append(["get_results_success", time.time() - start])
        return results.filter(pl.col("success"))
    elif scope == "fail":
        log.append(["get_results_fail", time.time() - start])
        return results.filter(~pl.col("success"))
    elif scope == "hard_fail":
        log.append(["get_results_hard_fail", time.time() - start])
        return results.filter(pl.col("hard_fail"))
    else:
        log.append(["get_results_default", time.time() - start])
        return results


def pick_leaf(leaves, pdf):
    start = time.time()
    result: tuple | None = None
    if isinstance(leaves, dict):
        for key, leaf in leaves.items():
            config = leaf.config
            leaf_result = get_results(pdf, "pick", config, scope="success")
            if len(leaf_result) > 0:
                result = (leaf, key)
                break
    elif isinstance(leaves, list):
        for leaf in leaves:
            config = leaf.config
            leaf_result = get_results(pdf, "pick", config, scope="success")
            if len(leaf_result) > 0:
                result = (leaf, "")
                break
    else:
        raise TypeError("the pick_leaf() function requires leaves to be a dictionary or list")
    if not result:
        raise StatementError("the account cannot be identified from your statement")
    log.append(["pick_leaf", time.time() - start])
    return result


def get_config_from_account(account_key, file_path):
    start = time.time()
    config_account = config_accounts.get(account_key)
    if not config_account:
        raise StatementError(f"Unable to identify the account from the statement provided: {file_path}")
    else:
        log.append(["get_config_from_account", time.time() - start])
        return config_account


def get_config_from_company(company_key, pdf, file_path):
    start = time.time()
    company_accounts = None
    config_account = None
    try:
        company_accounts = config_company_accounts(company_key)
    except KeyError:
        print(f"{company_key} is not a valid company key")
    if company_accounts:
        try:
            config_account = pick_leaf(leaves=company_accounts, pdf=pdf)[0]
        except StatementError:
            config_account = None
    if not config_account:
        raise StatementError(f"Unable to identify the account from the statement provided: {file_path}")
    log.append(["get_config_from_company", time.time() - start])
    return config_account


def get_config_from_statement(pdf, file_path):
    start = time.time()
    company_leaf = pick_leaf(leaves=config_companies, pdf=pdf)
    if not company_leaf:
        raise StatementError(f"Unable to identify the company from the statement provided: {file_path}")
    company_key = company_leaf[1]
    config_account = None
    try:
        config_account = get_config_from_company(company_key, pdf, file_path)
    except Exception as e:
        raise StatementError(f"Unable to identify the account from the statement provided: {file_path}") from e
    log.append(["get_config_from_statement", time.time() - start])
    return config_account


def get_config(self):
    start = time.time()
    config = None
    if self.account_key:
        config = get_config_from_account(self.account_key, self.file_path)
    elif self.company_key:
        config = get_config_from_company(self.company_key, self.pdf, self.file_path)
    else:
        config = get_config_from_statement(self.pdf, self.file_path)
    log.append(["get_config", time.time() - start])
    return config


def get_standard_fields(data, section):
    global checks_and_balances
    for std_field, std_config in config_standard_fields.items():
        if std_config.section == section:
            ref = [ref for ref in std_config.std_refs if ref.statement_type == statement_type][0]
            if ref:
                data = data.with_columns(pl.col(ref.field).alias(std_field))
                if std_config.type == "numeric":
                    # if we have credits and debits in the same column we might need to exclude positive or negative values
                    data = data.with_columns(
                        pl.when(ref.exclude_negative_values & (pl.col(std_field).cast(float) < 0.0000))
                        .then(pl.lit(0.0000))
                        .otherwise(pl.col(std_field))
                        .alias(std_field)
                    ).with_columns(
                        pl.when(ref.exclude_positive_values & (pl.col(std_field).cast(float) > 0.0000))
                        .then(pl.lit(0.0000))
                        .otherwise(pl.col(std_field))
                        .alias(std_field)
                    )
                    data = data.with_columns(
                        pl.col(std_field)
                        .fill_null(0.0000)
                        .cast(float)
                        .mul(ref.multiplier)
                        .cast(str)
                        .str.to_decimal(scale=4)
                        .alias(std_field)
                    )
                    # if std_config.type == "decimal":
                    #     data.with_columns(pl.col(std_field).cast(str).str.to_decimal(scale=2).alias(std_field))
                elif std_config.type == "date" and ref.format:
                    try:
                        data = data.with_columns(pl.col(std_field).str.to_date(format=ref.format))
                    except pl.exceptions.InvalidOperationError:  # failure to cast as a date
                        try:  # try removing the middle bit if the statement date is something like '9 July to 8 August 2025'
                            data = data.with_columns(
                                pl.col(std_field)
                                .str.split(by=" ")
                                .list.gather([0, 1, 5])
                                .list.join(separator=" ")
                                .str.to_date(format=ref.format)
                            )
                        except pl.exceptions.InvalidOperationError:  # still failed?
                            continue  # give up and return the date as it is
    if section == "pages":
        data = data.with_columns(STD_PAGE_NUMBER=pl.col("page"))
    if section == "lines":
        data = data.join(checks_and_balances.select(pl.col("STD_OPENING_BALANCE").alias("STD_RUNNING_BALANCE")), how="cross")
        data = data.with_columns(STD_MOVEMENT=pl.col("STD_PAYMENT_IN").sub("STD_PAYMENT_OUT")).with_columns(
            STD_RUNNING_BALANCE=pl.col("STD_RUNNING_BALANCE").add(pl.col("STD_MOVEMENT").cum_sum())
        )
    # Checks & Balances updates
    if section == "header":
        checks_and_balances = checks_and_balances.hstack(
            data.select("STD_CLOSING_BALANCE", "STD_OPENING_BALANCE", "STD_PAYMENTS_IN", "STD_PAYMENTS_OUT")
        )
        checks_and_balances = checks_and_balances.with_columns(
            STD_STATEMENT_MOVEMENT=pl.col("STD_CLOSING_BALANCE").sub("STD_OPENING_BALANCE"),
            STD_BALANCE_OF_PAYMENTS=pl.col("STD_PAYMENTS_IN").sub("STD_PAYMENTS_OUT"),
        )
    if section == "lines":
        checks_and_balances = checks_and_balances.hstack(data.select("STD_PAYMENT_IN", "STD_PAYMENT_OUT", "STD_MOVEMENT").sum())
        checks_and_balances = checks_and_balances.hstack(data.select(pl.last("STD_RUNNING_BALANCE")))
    return data


start_all = time.time()

config = get_config(stmt)
company = config.company.company if config.company and hasattr(config.company, "company") else ""
account = config.account if config and hasattr(config, "account") else ""
statement_type = (
    config.statement_type.statement_type if config.statement_type and hasattr(config.statement_type, "statement_type") else None
)
config_header = config.statement_type.header.configs if config.statement_type and hasattr(config.statement_type, "header") else None
config_pages = config.statement_type.pages.configs if config.statement_type and hasattr(config.statement_type, "pages") else None
config_lines = config.statement_type.lines.configs if config.statement_type and hasattr(config.statement_type, "lines") else None

start_header = time.time()

if config_header:
    results: pl.DataFrame = pl.DataFrame()
    for config in config_header:
        results.vstack(get_results(stmt.pdf, "header", config, scope="success"), in_place=True)
    results = results.pivot(values="value", index="section", on="field")
    results = results.pipe(get_standard_fields, "header")
    with pl.Config(tbl_cols=-1, tbl_rows=-1):
        print(results)
        # print(checks_and_balances)
    ...


end_header = time.time()
start_pages = time.time()

if config_pages:
    results: pl.DataFrame = pl.DataFrame()
    for config in config_pages:
        results.vstack(get_results(stmt.pdf, "pages", config, scope="success"), in_place=True)
    results = results.pipe(get_standard_fields, "pages")
    with pl.Config(tbl_cols=-1, tbl_rows=-1):
        print(results)
        # print(checks_and_balances)
end_pages = time.time()

start_lines = time.time()

if config_lines:
    results: pl.DataFrame = pl.DataFrame()
    for config in config_lines:
        results.vstack(get_results(stmt.pdf, "lines", config, scope="success"), in_place=True)
    results = results.pipe(get_standard_fields, "lines")
    with pl.Config(tbl_cols=-1, tbl_rows=-1):
        print(results)
        # print(checks_and_balances)
end_lines = time.time()


log.append(["Total Time", time.time() - start_all])

log_times = (
    pl.DataFrame(log, strict=False)
    .transpose(column_names=["function", "seconds"])
    .group_by(pl.col("function"))
    .agg(total_seconds=pl.col("seconds").cast(float).fill_null(0).sum(), total_calls=pl.col("function").count())
    .sort("total_seconds", descending=True)
)

# with pl.Config(tbl_cols=-1, tbl_rows=-1):
#     print(log_times)


# checks and balances
checks_and_balances = checks_and_balances.with_columns(
    BAL_PAYMENTS_IN=pl.when(pl.col("STD_PAYMENTS_IN").sub(pl.col("STD_PAYMENT_IN")) == 0).then(pl.lit(True)).otherwise(pl.lit(False)),
    BAL_PAYMENTS_OUT=pl.when(pl.col("STD_PAYMENTS_OUT").sub(pl.col("STD_PAYMENT_OUT")) == 0).then(pl.lit(True)).otherwise(pl.lit(False)),
    BAL_MOVEMENT=pl.when(
        (pl.col("STD_STATEMENT_MOVEMENT").sub(pl.col("STD_MOVEMENT")) == 0)
        & (pl.col("STD_MOVEMENT").sub(pl.col("STD_BALANCE_OF_PAYMENTS")) == 0)
    )
    .then(pl.lit(True))
    .otherwise(pl.lit(False)),
    BAL_CLOSING=pl.when(pl.col("STD_CLOSING_BALANCE").sub(pl.col("STD_RUNNING_BALANCE")) == 0).then(pl.lit(True)).otherwise(pl.lit(False)),
)

with pl.Config(tbl_cols=-1, tbl_rows=-1):
    print(checks_and_balances)
